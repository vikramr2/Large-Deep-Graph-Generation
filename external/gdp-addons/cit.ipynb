{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzOkWOZE3_Ug",
    "outputId": "9365d847-1919-4e22-f69a-cc7bac1a9313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA available: False\n",
      "CUDA Version PyTorch can see: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikram/Documents/School/CS598YOU/Large-Deep-Graph-Generation/bigg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Version PyTorch can see: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JPBxYyZ4IjH",
    "outputId": "b250ed42-566c-4234-a94f-c7e55b90673d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.0.1+cu118 in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision==0.15.2+cu118 in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: torchaudio==2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.1.4)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (2.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (11.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.30.5)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1+cu118) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch 2.0.1 with CUDA 11.8\n",
    "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5JYdSjO4KMV",
    "outputId": "239ae9be-5115-41d0-e038-18c6445ed23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
      "Collecting torch-scatter\n",
      "  Using cached https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.2+pt20cu118\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
      "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt20cu118)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
      "Collecting torch-cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.26.4)\n",
      "Installing collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.6.3+pt20cu118\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
      "Collecting torch-spline-conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (886 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.6/886.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
      "Successfully installed torch-spline-conv-1.2.2+pt20cu118\n",
      "Collecting torch-geometric==2.3.1\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.3.1) (4.66.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.3.1) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.3.1) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.3.1) (3.1.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.3.1) (2.32.3)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.3.1) (3.2.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.3.1) (1.5.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.3.1) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.3.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.3.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.3.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.3.1) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.3.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.3.1) (3.5.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910447 sha256=c581330fe6788f7fe4523ed1302a4ab00fc96bdd748ee1e7644f7a435dd90547\n",
      "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.3.1\n"
     ]
    }
   ],
   "source": [
    "# Install PyG dependencies\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "\n",
    "# Install PyTorch Geometric\n",
    "!pip install torch-geometric==2.3.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5m1zgyH4P4M",
    "outputId": "4d4415a4-c371-487b-a2f4-e786214c7cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement dgl-cu118==0.9.1 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for dgl-cu118==0.9.1\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install DGL 0.9.1 with CUDA 11.8\n",
    "!pip install dgl-cu118==0.9.1 -f https://data.dgl.ai/wheels/repo.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMIO05rI4SiM",
    "outputId": "4c418189-ca7e-453f-ab86-541d0756814b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl==0.9.1\n",
      "  Downloading dgl-0.9.1-cp310-cp310-manylinux1_x86_64.whl.metadata (557 bytes)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.1) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.1) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.1) (3.4.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.1) (4.66.6)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.1) (5.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.9.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.9.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.9.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.9.1) (2024.8.30)\n",
      "Downloading dgl-0.9.1-cp310-cp310-manylinux1_x86_64.whl (4.9 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/4.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/4.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dgl\n",
      "Successfully installed dgl-0.9.1\n"
     ]
    }
   ],
   "source": [
    "# Install DGL without CUDA\n",
    "!pip install dgl==0.9.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48lRd8CL4U3L",
    "outputId": "23634ce2-9ca9-4ba8-b85c-3193bdfd65b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
      "Collecting ml-collections\n",
      "  Downloading ml_collections-1.0.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Collecting torchdiffeq\n",
      "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml-collections) (1.16.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.0.1+cu118)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.13.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.4)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->torchdiffeq) (3.30.5)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->torchdiffeq) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
      "Downloading ml_collections-1.0.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: ml-collections, torchdiffeq\n",
      "Successfully installed ml-collections-1.0.0 torchdiffeq-0.2.5\n"
     ]
    }
   ],
   "source": [
    "# Install additional dependencies\n",
    "!pip install absl-py ml-collections pandas matplotlib tensorboard torchdiffeq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fO3wm_jD4W-h",
    "outputId": "105bde57-3d2d-41f6-c9cd-9f463ea79a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biscXAqT4ZPQ",
    "outputId": "2b6c151a-5f93-461a-d057-cb29c45c7771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at /content/drive/My Drive/GraphGDP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "graphgdp_path = '/content/drive/My Drive/GraphGDP'\n",
    "if not os.path.exists(graphgdp_path):\n",
    "    os.makedirs(graphgdp_path)\n",
    "    print(f\"Created folder at {graphgdp_path}\")\n",
    "    !git clone https://github.com/GRAPH-0/GraphGDP.git \"$graphgdp_path\"\n",
    "else:\n",
    "    print(f\"Folder already exists at {graphgdp_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28ZAPZ0D4aze",
    "outputId": "95094154-13bf-427f-ef81-3eea6563ec61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/GraphGDP\n"
     ]
    }
   ],
   "source": [
    "%cd \"/content/drive/My Drive/GraphGDP\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xE0JBlxCnLFO",
    "outputId": "281d991a-b322-44e4-d177-650fb6372a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'list'>\n",
      "Number of items in dataset: 52\n",
      "First graph/item details:\n",
      "Graph with 507 nodes and 6844 edges\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "with open('/content/drive/MyDrive/GraphGDP/data/cit-HepPh.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "# Inspect the dataset type and structure\n",
    "print(\"Dataset type:\", type(dataset))\n",
    "print(\"Number of items in dataset:\", len(dataset))\n",
    "\n",
    "# Inspect the first graph/item\n",
    "print(\"First graph/item details:\")\n",
    "print(dataset[0])\n",
    "\n",
    "# If the dataset contains additional nested structures\n",
    "if isinstance(dataset[0], dict):\n",
    "    print(\"Keys in the first item:\", dataset[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjjuRnvh4cBY",
    "outputId": "ef4b0757-dd92-43be-f1b9-25d261cdea44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 05:25:07.721618: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-05 05:25:07.740622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-05 05:25:07.761685: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-05 05:25:07.768096: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 05:25:07.783179: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 05:25:08.833806: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "W1205 05:25:12.382062 139773683659392 utils.py:76] No checkpoint found at /content/drive/My Drive/GraphGDP/outputcitreal/checkpoints-meta/checkpoint.pth. Returned the same state as input\n",
      "I1205 05:25:12.449293 139773683659392 run_lib.py:118] Starting training loop at step 0.\n",
      "I1205 05:25:13.296893 139773683659392 run_lib.py:131] step: 0, training_loss: 1.00568e+00\n",
      "I1205 05:25:13.548705 139773683659392 run_lib.py:144] step: 0, eval_loss: 1.00761e+00\n",
      "I1205 05:25:13.655349 139773683659392 run_lib.py:144] step: 0, eval_loss: 1.01132e+00\n",
      "I1205 05:25:13.856724 139773683659392 run_lib.py:150] step: 0, test_loss: 1.00815e+00\n",
      "I1205 05:25:13.963830 139773683659392 run_lib.py:150] step: 0, test_loss: 1.00934e+00\n",
      "I1205 05:26:11.855931 139773683659392 run_lib.py:131] step: 200, training_loss: 1.00050e+00\n",
      "I1205 05:27:09.432920 139773683659392 run_lib.py:131] step: 400, training_loss: 9.74675e-01\n",
      "I1205 05:28:06.795048 139773683659392 run_lib.py:131] step: 600, training_loss: 9.31803e-01\n",
      "I1205 05:29:04.395880 139773683659392 run_lib.py:131] step: 800, training_loss: 6.26654e-01\n",
      "I1205 05:30:01.958325 139773683659392 run_lib.py:131] step: 1000, training_loss: 6.39297e-01\n",
      "I1205 05:30:59.215481 139773683659392 run_lib.py:131] step: 1200, training_loss: 3.40340e-01\n",
      "I1205 05:31:56.801873 139773683659392 run_lib.py:131] step: 1400, training_loss: 1.99081e-01\n",
      "I1205 05:32:54.434827 139773683659392 run_lib.py:131] step: 1600, training_loss: 4.49813e-01\n",
      "I1205 05:33:51.721877 139773683659392 run_lib.py:131] step: 1800, training_loss: 1.59623e-01\n",
      "I1205 05:34:49.389820 139773683659392 run_lib.py:131] step: 2000, training_loss: 2.04753e-01\n",
      "I1205 05:35:46.935009 139773683659392 run_lib.py:131] step: 2200, training_loss: 1.20663e-01\n",
      "I1205 05:36:44.248256 139773683659392 run_lib.py:131] step: 2400, training_loss: 2.19329e-01\n",
      "I1205 05:37:41.978098 139773683659392 run_lib.py:131] step: 2600, training_loss: 2.19021e-01\n",
      "I1205 05:38:39.564477 139773683659392 run_lib.py:131] step: 2800, training_loss: 2.75239e-01\n",
      "I1205 05:39:36.964727 139773683659392 run_lib.py:131] step: 3000, training_loss: 1.40021e-01\n",
      "I1205 05:40:34.644153 139773683659392 run_lib.py:131] step: 3200, training_loss: 9.91178e-02\n",
      "I1205 05:41:32.297035 139773683659392 run_lib.py:131] step: 3400, training_loss: 1.04077e-01\n",
      "I1205 05:42:29.640836 139773683659392 run_lib.py:131] step: 3600, training_loss: 1.92406e-01\n",
      "I1205 05:43:27.254431 139773683659392 run_lib.py:131] step: 3800, training_loss: 1.88070e-01\n",
      "I1205 05:44:24.909841 139773683659392 run_lib.py:131] step: 4000, training_loss: 1.58968e-01\n",
      "I1205 05:45:22.249161 139773683659392 run_lib.py:131] step: 4200, training_loss: 2.57738e-01\n",
      "I1205 05:46:19.815567 139773683659392 run_lib.py:131] step: 4400, training_loss: 1.61445e-01\n",
      "I1205 05:47:17.425055 139773683659392 run_lib.py:131] step: 4600, training_loss: 1.32681e-01\n",
      "I1205 05:48:14.774015 139773683659392 run_lib.py:131] step: 4800, training_loss: 1.56797e-01\n",
      "I1205 05:49:12.346457 139773683659392 run_lib.py:131] step: 5000, training_loss: 2.30056e-01\n",
      "I1205 05:49:12.654402 139773683659392 run_lib.py:144] step: 5000, eval_loss: 2.06710e-01\n",
      "I1205 05:49:12.756773 139773683659392 run_lib.py:144] step: 5000, eval_loss: 5.82692e-02\n",
      "I1205 05:49:12.961584 139773683659392 run_lib.py:150] step: 5000, test_loss: 8.71333e-02\n",
      "I1205 05:49:13.068887 139773683659392 run_lib.py:150] step: 5000, test_loss: 5.89752e-02\n",
      "I1205 05:50:10.807509 139773683659392 run_lib.py:131] step: 5200, training_loss: 9.09608e-02\n",
      "I1205 05:51:08.242418 139773683659392 run_lib.py:131] step: 5400, training_loss: 7.62832e-02\n",
      "I1205 05:52:06.007458 139773683659392 run_lib.py:131] step: 5600, training_loss: 8.89058e-02\n",
      "I1205 05:53:03.794122 139773683659392 run_lib.py:131] step: 5800, training_loss: 5.75862e-02\n",
      "I1205 05:54:01.237568 139773683659392 run_lib.py:131] step: 6000, training_loss: 9.62737e-02\n",
      "I1205 05:54:58.957388 139773683659392 run_lib.py:131] step: 6200, training_loss: 7.67466e-02\n",
      "I1205 05:55:56.769042 139773683659392 run_lib.py:131] step: 6400, training_loss: 8.47521e-02\n",
      "I1205 05:56:54.337558 139773683659392 run_lib.py:131] step: 6600, training_loss: 1.85986e-01\n",
      "I1205 05:57:52.233527 139773683659392 run_lib.py:131] step: 6800, training_loss: 9.86340e-02\n",
      "I1205 05:58:50.076508 139773683659392 run_lib.py:131] step: 7000, training_loss: 5.59434e-02\n",
      "I1205 05:59:47.511871 139773683659392 run_lib.py:131] step: 7200, training_loss: 6.89058e-02\n",
      "I1205 06:00:45.332057 139773683659392 run_lib.py:131] step: 7400, training_loss: 6.97689e-02\n",
      "I1205 06:01:43.226954 139773683659392 run_lib.py:131] step: 7600, training_loss: 7.90469e-02\n",
      "I1205 06:02:40.744132 139773683659392 run_lib.py:131] step: 7800, training_loss: 8.56338e-02\n",
      "I1205 06:03:38.497541 139773683659392 run_lib.py:131] step: 8000, training_loss: 8.60655e-02\n",
      "I1205 06:04:36.466980 139773683659392 run_lib.py:131] step: 8200, training_loss: 1.14223e-01\n",
      "I1205 06:05:33.934343 139773683659392 run_lib.py:131] step: 8400, training_loss: 1.22798e-01\n",
      "I1205 06:06:31.751817 139773683659392 run_lib.py:131] step: 8600, training_loss: 7.63413e-02\n",
      "I1205 06:07:29.654526 139773683659392 run_lib.py:131] step: 8800, training_loss: 1.07675e-01\n",
      "I1205 06:08:27.411119 139773683659392 run_lib.py:131] step: 9000, training_loss: 1.36298e-01\n",
      "I1205 06:09:25.275396 139773683659392 run_lib.py:131] step: 9200, training_loss: 4.86294e-02\n",
      "I1205 06:10:23.115723 139773683659392 run_lib.py:131] step: 9400, training_loss: 6.06022e-02\n",
      "I1205 06:11:20.585250 139773683659392 run_lib.py:131] step: 9600, training_loss: 6.14401e-02\n",
      "I1205 06:12:18.245184 139773683659392 run_lib.py:131] step: 9800, training_loss: 1.12595e-01\n",
      "I1205 06:13:15.960891 139773683659392 run_lib.py:131] step: 10000, training_loss: 7.28424e-02\n",
      "I1205 06:13:16.268990 139773683659392 run_lib.py:144] step: 10000, eval_loss: 8.79901e-02\n",
      "I1205 06:13:16.372688 139773683659392 run_lib.py:144] step: 10000, eval_loss: 2.69135e-02\n",
      "I1205 06:13:16.574951 139773683659392 run_lib.py:150] step: 10000, test_loss: 5.30900e-02\n",
      "I1205 06:13:16.681238 139773683659392 run_lib.py:150] step: 10000, test_loss: 7.36138e-02\n",
      "I1205 06:16:07.618756 139773683659392 run_lib.py:131] step: 10200, training_loss: 5.69541e-02\n",
      "I1205 06:17:06.199494 139773683659392 run_lib.py:131] step: 10400, training_loss: 4.84154e-02\n",
      "I1205 06:18:04.854222 139773683659392 run_lib.py:131] step: 10600, training_loss: 6.37285e-02\n",
      "I1205 06:19:03.196079 139773683659392 run_lib.py:131] step: 10800, training_loss: 4.80476e-02\n",
      "I1205 06:20:01.819369 139773683659392 run_lib.py:131] step: 11000, training_loss: 1.27836e-01\n",
      "I1205 06:21:00.296955 139773683659392 run_lib.py:131] step: 11200, training_loss: 6.13115e-02\n",
      "I1205 06:21:58.686199 139773683659392 run_lib.py:131] step: 11400, training_loss: 6.40412e-02\n",
      "I1205 06:22:57.225538 139773683659392 run_lib.py:131] step: 11600, training_loss: 4.99627e-02\n",
      "I1205 06:23:55.886012 139773683659392 run_lib.py:131] step: 11800, training_loss: 5.60754e-02\n",
      "I1205 06:24:54.300734 139773683659392 run_lib.py:131] step: 12000, training_loss: 6.23755e-02\n",
      "I1205 06:25:52.869554 139773683659392 run_lib.py:131] step: 12200, training_loss: 7.44198e-02\n",
      "I1205 06:26:51.383106 139773683659392 run_lib.py:131] step: 12400, training_loss: 5.23632e-02\n",
      "I1205 06:27:49.775610 139773683659392 run_lib.py:131] step: 12600, training_loss: 4.66480e-02\n",
      "I1205 06:28:48.389947 139773683659392 run_lib.py:131] step: 12800, training_loss: 4.38801e-02\n",
      "I1205 06:29:47.060080 139773683659392 run_lib.py:131] step: 13000, training_loss: 4.90238e-02\n",
      "I1205 06:30:45.315780 139773683659392 run_lib.py:131] step: 13200, training_loss: 7.53024e-02\n",
      "I1205 06:31:44.187012 139773683659392 run_lib.py:131] step: 13400, training_loss: 6.30444e-02\n",
      "I1205 06:32:42.847039 139773683659392 run_lib.py:131] step: 13600, training_loss: 5.99054e-02\n",
      "I1205 06:33:41.246366 139773683659392 run_lib.py:131] step: 13800, training_loss: 7.92275e-02\n",
      "I1205 06:34:39.800483 139773683659392 run_lib.py:131] step: 14000, training_loss: 4.75110e-02\n",
      "I1205 06:35:38.330435 139773683659392 run_lib.py:131] step: 14200, training_loss: 4.95486e-02\n",
      "I1205 06:36:36.653478 139773683659392 run_lib.py:131] step: 14400, training_loss: 6.30164e-02\n",
      "I1205 06:37:35.061020 139773683659392 run_lib.py:131] step: 14600, training_loss: 6.63830e-02\n",
      "I1205 06:38:33.597301 139773683659392 run_lib.py:131] step: 14800, training_loss: 1.10991e-01\n",
      "I1205 06:39:31.902786 139773683659392 run_lib.py:131] step: 15000, training_loss: 4.06457e-02\n",
      "I1205 06:39:32.214978 139773683659392 run_lib.py:144] step: 15000, eval_loss: 4.88802e-02\n",
      "I1205 06:39:32.317438 139773683659392 run_lib.py:144] step: 15000, eval_loss: 6.82095e-02\n",
      "I1205 06:39:32.525809 139773683659392 run_lib.py:150] step: 15000, test_loss: 3.67889e-02\n",
      "I1205 06:39:32.634100 139773683659392 run_lib.py:150] step: 15000, test_loss: 5.36048e-02\n",
      "I1205 06:40:31.186229 139773683659392 run_lib.py:131] step: 15200, training_loss: 5.18297e-02\n",
      "I1205 06:41:29.656399 139773683659392 run_lib.py:131] step: 15400, training_loss: 5.43821e-02\n",
      "I1205 06:42:27.861008 139773683659392 run_lib.py:131] step: 15600, training_loss: 3.68063e-02\n",
      "I1205 06:43:26.667290 139773683659392 run_lib.py:131] step: 15800, training_loss: 5.50814e-02\n",
      "I1205 06:44:25.377129 139773683659392 run_lib.py:131] step: 16000, training_loss: 4.61619e-02\n",
      "I1205 06:45:23.621330 139773683659392 run_lib.py:131] step: 16200, training_loss: 4.37101e-02\n",
      "I1205 06:46:22.388667 139773683659392 run_lib.py:131] step: 16400, training_loss: 7.77398e-02\n",
      "I1205 06:47:20.926397 139773683659392 run_lib.py:131] step: 16600, training_loss: 6.14854e-02\n",
      "I1205 06:48:19.170191 139773683659392 run_lib.py:131] step: 16800, training_loss: 5.43793e-02\n",
      "I1205 06:49:17.680278 139773683659392 run_lib.py:131] step: 17000, training_loss: 3.60631e-02\n",
      "I1205 06:50:16.216440 139773683659392 run_lib.py:131] step: 17200, training_loss: 4.41816e-02\n",
      "I1205 06:51:14.369232 139773683659392 run_lib.py:131] step: 17400, training_loss: 9.06669e-02\n",
      "I1205 06:52:12.999354 139773683659392 run_lib.py:131] step: 17600, training_loss: 4.07459e-02\n",
      "I1205 06:53:11.527661 139773683659392 run_lib.py:131] step: 17800, training_loss: 3.18419e-02\n",
      "I1205 06:54:09.936892 139773683659392 run_lib.py:131] step: 18000, training_loss: 5.83783e-02\n",
      "I1205 06:55:08.531959 139773683659392 run_lib.py:131] step: 18200, training_loss: 4.71145e-02\n",
      "I1205 06:56:07.202661 139773683659392 run_lib.py:131] step: 18400, training_loss: 3.66056e-02\n",
      "I1205 06:57:05.548154 139773683659392 run_lib.py:131] step: 18600, training_loss: 1.31155e-01\n",
      "I1205 06:58:03.933886 139773683659392 run_lib.py:131] step: 18800, training_loss: 4.40894e-02\n",
      "I1205 06:59:02.269052 139773683659392 run_lib.py:131] step: 19000, training_loss: 4.92363e-02\n",
      "I1205 07:00:00.463515 139773683659392 run_lib.py:131] step: 19200, training_loss: 7.45170e-02\n",
      "I1205 07:00:58.820798 139773683659392 run_lib.py:131] step: 19400, training_loss: 4.37358e-02\n",
      "I1205 07:01:57.290910 139773683659392 run_lib.py:131] step: 19600, training_loss: 4.72483e-02\n",
      "I1205 07:02:55.517521 139773683659392 run_lib.py:131] step: 19800, training_loss: 5.20168e-02\n",
      "I1205 07:03:54.053938 139773683659392 run_lib.py:131] step: 20000, training_loss: 1.43904e-01\n",
      "I1205 07:03:54.365792 139773683659392 run_lib.py:144] step: 20000, eval_loss: 6.48274e-02\n",
      "I1205 07:03:54.470758 139773683659392 run_lib.py:144] step: 20000, eval_loss: 4.51277e-02\n",
      "I1205 07:03:54.669994 139773683659392 run_lib.py:150] step: 20000, test_loss: 6.59441e-02\n",
      "I1205 07:03:54.780444 139773683659392 run_lib.py:150] step: 20000, test_loss: 5.63224e-02\n",
      "I1205 07:07:17.055657 139773683659392 run_lib.py:131] step: 20200, training_loss: 5.21297e-02\n",
      "I1205 07:08:15.083544 139773683659392 run_lib.py:131] step: 20400, training_loss: 6.93332e-02\n",
      "I1205 07:09:13.551928 139773683659392 run_lib.py:131] step: 20600, training_loss: 5.61552e-02\n",
      "I1205 07:10:12.050357 139773683659392 run_lib.py:131] step: 20800, training_loss: 4.39672e-02\n",
      "I1205 07:11:10.238081 139773683659392 run_lib.py:131] step: 21000, training_loss: 4.54056e-02\n",
      "I1205 07:12:08.667106 139773683659392 run_lib.py:131] step: 21200, training_loss: 4.09091e-02\n",
      "I1205 07:13:06.975080 139773683659392 run_lib.py:131] step: 21400, training_loss: 4.31208e-02\n",
      "I1205 07:14:05.094263 139773683659392 run_lib.py:131] step: 21600, training_loss: 3.45440e-02\n",
      "I1205 07:15:03.432772 139773683659392 run_lib.py:131] step: 21800, training_loss: 6.65678e-02\n",
      "I1205 07:16:01.762491 139773683659392 run_lib.py:131] step: 22000, training_loss: 5.78904e-02\n",
      "I1205 07:16:59.847611 139773683659392 run_lib.py:131] step: 22200, training_loss: 1.07418e-01\n",
      "I1205 07:17:58.286586 139773683659392 run_lib.py:131] step: 22400, training_loss: 5.67339e-02\n",
      "I1205 07:18:56.632840 139773683659392 run_lib.py:131] step: 22600, training_loss: 8.94378e-02\n",
      "I1205 07:19:54.699402 139773683659392 run_lib.py:131] step: 22800, training_loss: 4.27714e-02\n",
      "I1205 07:20:53.144567 139773683659392 run_lib.py:131] step: 23000, training_loss: 5.68305e-02\n",
      "I1205 07:21:51.478166 139773683659392 run_lib.py:131] step: 23200, training_loss: 4.06424e-02\n",
      "I1205 07:22:49.652589 139773683659392 run_lib.py:131] step: 23400, training_loss: 7.30969e-02\n",
      "I1205 07:23:48.136180 139773683659392 run_lib.py:131] step: 23600, training_loss: 4.75925e-02\n",
      "I1205 07:24:46.470029 139773683659392 run_lib.py:131] step: 23800, training_loss: 6.19893e-02\n",
      "I1205 07:25:44.523593 139773683659392 run_lib.py:131] step: 24000, training_loss: 7.12167e-02\n",
      "I1205 07:26:42.799822 139773683659392 run_lib.py:131] step: 24200, training_loss: 5.24594e-02\n",
      "I1205 07:27:41.154370 139773683659392 run_lib.py:131] step: 24400, training_loss: 5.15623e-02\n",
      "I1205 07:28:39.288486 139773683659392 run_lib.py:131] step: 24600, training_loss: 4.06195e-02\n",
      "I1205 07:29:37.699567 139773683659392 run_lib.py:131] step: 24800, training_loss: 8.47719e-02\n",
      "I1205 07:30:36.094458 139773683659392 run_lib.py:131] step: 25000, training_loss: 5.02746e-02\n",
      "I1205 07:30:36.412053 139773683659392 run_lib.py:144] step: 25000, eval_loss: 2.89268e-02\n",
      "I1205 07:30:36.515992 139773683659392 run_lib.py:144] step: 25000, eval_loss: 3.27027e-02\n",
      "I1205 07:30:36.722885 139773683659392 run_lib.py:150] step: 25000, test_loss: 5.32039e-02\n",
      "I1205 07:30:36.832880 139773683659392 run_lib.py:150] step: 25000, test_loss: 4.54276e-02\n",
      "I1205 07:31:35.031140 139773683659392 run_lib.py:131] step: 25200, training_loss: 4.67884e-02\n",
      "I1205 07:32:33.501221 139773683659392 run_lib.py:131] step: 25400, training_loss: 1.06213e-01\n",
      "I1205 07:33:31.972218 139773683659392 run_lib.py:131] step: 25600, training_loss: 3.84486e-02\n",
      "I1205 07:34:30.244364 139773683659392 run_lib.py:131] step: 25800, training_loss: 5.22449e-02\n",
      "I1205 07:35:28.566048 139773683659392 run_lib.py:131] step: 26000, training_loss: 5.93606e-02\n",
      "I1205 07:36:27.108083 139773683659392 run_lib.py:131] step: 26200, training_loss: 6.69297e-02\n",
      "I1205 07:37:25.465034 139773683659392 run_lib.py:131] step: 26400, training_loss: 3.80392e-02\n",
      "I1205 07:38:23.997553 139773683659392 run_lib.py:131] step: 26600, training_loss: 3.01042e-02\n",
      "I1205 07:39:22.532874 139773683659392 run_lib.py:131] step: 26800, training_loss: 5.46738e-02\n",
      "I1205 07:40:20.636117 139773683659392 run_lib.py:131] step: 27000, training_loss: 4.97149e-02\n",
      "I1205 07:41:18.979757 139773683659392 run_lib.py:131] step: 27200, training_loss: 6.47688e-02\n",
      "I1205 07:42:17.329792 139773683659392 run_lib.py:131] step: 27400, training_loss: 2.57665e-02\n",
      "I1205 07:43:15.493250 139773683659392 run_lib.py:131] step: 27600, training_loss: 4.42274e-02\n",
      "I1205 07:44:13.949606 139773683659392 run_lib.py:131] step: 27800, training_loss: 5.40164e-02\n",
      "I1205 07:45:12.309909 139773683659392 run_lib.py:131] step: 28000, training_loss: 6.00941e-02\n",
      "I1205 07:46:10.398215 139773683659392 run_lib.py:131] step: 28200, training_loss: 1.17772e-01\n",
      "I1205 07:47:08.801253 139773683659392 run_lib.py:131] step: 28400, training_loss: 3.23177e-02\n",
      "I1205 07:48:07.151478 139773683659392 run_lib.py:131] step: 28600, training_loss: 3.78347e-02\n",
      "I1205 07:49:05.296569 139773683659392 run_lib.py:131] step: 28800, training_loss: 3.78597e-02\n",
      "I1205 07:50:03.645520 139773683659392 run_lib.py:131] step: 29000, training_loss: 4.78675e-02\n",
      "I1205 07:51:01.966887 139773683659392 run_lib.py:131] step: 29200, training_loss: 6.56650e-02\n",
      "I1205 07:52:00.063115 139773683659392 run_lib.py:131] step: 29400, training_loss: 3.01224e-02\n",
      "I1205 07:52:58.563056 139773683659392 run_lib.py:131] step: 29600, training_loss: 6.75924e-02\n",
      "I1205 07:53:57.148055 139773683659392 run_lib.py:131] step: 29800, training_loss: 3.77156e-02\n",
      "I1205 07:54:55.516375 139773683659392 run_lib.py:131] step: 30000, training_loss: 5.61423e-02\n",
      "I1205 07:54:55.836049 139773683659392 run_lib.py:144] step: 30000, eval_loss: 6.48134e-02\n",
      "I1205 07:54:55.941478 139773683659392 run_lib.py:144] step: 30000, eval_loss: 4.29173e-02\n",
      "I1205 07:54:56.148261 139773683659392 run_lib.py:150] step: 30000, test_loss: 4.28482e-02\n",
      "I1205 07:54:56.257356 139773683659392 run_lib.py:150] step: 30000, test_loss: 2.22412e-01\n",
      "I1205 07:58:31.801561 139773683659392 run_lib.py:131] step: 30200, training_loss: 5.50257e-02\n",
      "I1205 07:59:30.238967 139773683659392 run_lib.py:131] step: 30400, training_loss: 2.28938e-02\n",
      "I1205 08:00:28.596226 139773683659392 run_lib.py:131] step: 30600, training_loss: 4.68383e-02\n",
      "I1205 08:01:27.152011 139773683659392 run_lib.py:131] step: 30800, training_loss: 2.91662e-02\n",
      "I1205 08:02:25.750952 139773683659392 run_lib.py:131] step: 31000, training_loss: 6.07719e-02\n",
      "I1205 08:03:23.921432 139773683659392 run_lib.py:131] step: 31200, training_loss: 4.31300e-02\n",
      "I1205 08:04:22.525658 139773683659392 run_lib.py:131] step: 31400, training_loss: 4.49070e-02\n",
      "I1205 08:05:21.289998 139773683659392 run_lib.py:131] step: 31600, training_loss: 3.15845e-02\n",
      "I1205 08:06:19.666317 139773683659392 run_lib.py:131] step: 31800, training_loss: 3.68882e-02\n",
      "I1205 08:07:18.317620 139773683659392 run_lib.py:131] step: 32000, training_loss: 2.98375e-02\n",
      "I1205 08:08:16.724975 139773683659392 run_lib.py:131] step: 32200, training_loss: 5.49775e-02\n",
      "I1205 08:09:15.128798 139773683659392 run_lib.py:131] step: 32400, training_loss: 6.55495e-02\n",
      "I1205 08:10:13.724105 139773683659392 run_lib.py:131] step: 32600, training_loss: 5.19459e-02\n",
      "I1205 08:11:12.456652 139773683659392 run_lib.py:131] step: 32800, training_loss: 3.07436e-02\n",
      "I1205 08:12:10.832504 139773683659392 run_lib.py:131] step: 33000, training_loss: 4.57564e-02\n",
      "I1205 08:13:09.333081 139773683659392 run_lib.py:131] step: 33200, training_loss: 5.07758e-02\n",
      "I1205 08:14:07.917929 139773683659392 run_lib.py:131] step: 33400, training_loss: 5.33137e-02\n",
      "I1205 08:15:06.161284 139773683659392 run_lib.py:131] step: 33600, training_loss: 2.96971e-02\n",
      "I1205 08:16:04.843835 139773683659392 run_lib.py:131] step: 33800, training_loss: 5.45864e-02\n",
      "I1205 08:17:03.391026 139773683659392 run_lib.py:131] step: 34000, training_loss: 5.83528e-02\n",
      "I1205 08:18:01.693748 139773683659392 run_lib.py:131] step: 34200, training_loss: 2.63678e-02\n",
      "I1205 08:19:00.370133 139773683659392 run_lib.py:131] step: 34400, training_loss: 4.77508e-02\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config configs/vp_cit_pgsn.py --config.model.beta_max 5.0 --mode train --workdir \"outputcitreal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ou2APYo4dUQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bigg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
